{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "\n",
    "# Import Dependencies\n",
    "import tweepy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "# from matplotlib import style \n",
    "# style.use('ggplot')\n",
    "from datetime import datetime\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Twitter API Keys\n",
    "from BP_config import consumer_key , consumer_secret , access_token , access_token_secret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Sentiment Analyzer Vader\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Vader\n",
    "VaderSentimentAnalyzer = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup Tweepy API Authentication\n",
    "Authorization = tweepy.OAuthHandler(consumer_key , consumer_secret)\n",
    "Authorization.set_access_token(access_token , access_token_secret)\n",
    "apiRequests = tweepy.API(Authorization , parser = tweepy.parsers.JSONParser())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrive Tweet and Sentiment Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of Target Users (BBC, CBS, CNN, Fox, and New York times)\n",
    "TargetUsers = [\"@BBCWorld\", \"@CBSNews\", \"@CNN\", \"@FoxNews\", \"@nytimes\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create empty lists to store sentiments\n",
    "CompoundList = []\n",
    "PositiveList = []\n",
    "NegativeList = []\n",
    "NeutralList = []\n",
    "\n",
    "CreateDateList = []\n",
    "TweetsLagList = []\n",
    "NewsOutletList = []\n",
    "TweetTextList = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through the Target Users\n",
    "# x: News Outlet\n",
    "for x in TargetUsers:\n",
    "\n",
    "    # Tweet Counter\n",
    "    Counter = 0\n",
    "\n",
    "    # Retrieve the last 100 Tweets for Target User\n",
    "    # y: page\n",
    "    for y in range(5): \n",
    "\n",
    "        # Get tweets from the home feed\n",
    "        UserTweets = apiRequests.user_timeline(x , page = y)\n",
    "#         pprint(UserTweets)\n",
    "        \n",
    "        # Loop through tweets\n",
    "        # z: tweet\n",
    "        for z in UserTweets: \n",
    "\n",
    "            # Counter Update\n",
    "            Counter = Counter + 1\n",
    "\n",
    "            # Add tweet values to associated lists\n",
    "            TweetCreateDate = z[\"created_at\"]\n",
    "            TweetText = z[\"text\"]\n",
    "            \n",
    "#             print(f'{x}')\n",
    "#             print(f'{y}')           \n",
    "#             print(f'TweetCreateDate = {TweetCreateDate}')\n",
    "#             print(f'TweetText = {TweetText}')            \n",
    "\n",
    "            CreateDateList.append(TweetCreateDate)\n",
    "            TweetsLagList.append(Counter)\n",
    "            NewsOutletList.append(x)\n",
    "            TweetTextList.append(TweetText)\n",
    "            \n",
    "#             print(NewsOutletList)\n",
    "\n",
    "#             # Run Vader Analysis on each tweet\n",
    "            CompoundScore = VaderSentimentAnalyzer.polarity_scores(z[\"text\"])[\"compound\"]\n",
    "            PositiveScore = VaderSentimentAnalyzer.polarity_scores(z[\"text\"])[\"pos\"]\n",
    "            NegativeScore = VaderSentimentAnalyzer.polarity_scores(z[\"text\"])[\"neg\"]\n",
    "            NeutralScore = VaderSentimentAnalyzer.polarity_scores(z[\"text\"])[\"neu\"] \n",
    "            \n",
    "#             print(NeutralScore)\n",
    "\n",
    "            # Append to the Sentiment list           \n",
    "            CompoundList.append(CompoundScore)\n",
    "            PositiveList.append(PositiveScore)\n",
    "            NegativeList.append(NegativeScore)\n",
    "            NeutralList.append(NeutralScore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(CompoundList))\n",
    "print(len(PositiveList))\n",
    "print(len(NegativeList))\n",
    "print(len(NeutralList))\n",
    "print(len(CreateDateList))\n",
    "print(len(TweetsLagList))\n",
    "print(len(NewsOutletList))\n",
    "print(len(TweetTextList))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(CompoundList)\n",
    "# print(PositiveList)\n",
    "# print(NegativeList)\n",
    "# print(NeutralList)\n",
    "# print(CreateDateList)\n",
    "# print(TweetsLagList)\n",
    "# print(NewsOutletList)\n",
    "# print(TweetTextList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a data frame of the Tweet Lists created in earlier step\n",
    "NewsMood_DF = pd.DataFrame({\"News Outlet\"     : NewsOutletList\n",
    "                           ,\"Tweet Date\"      : CreateDateList\n",
    "                           ,\"Tweet Lag\"       : TweetsLagList\n",
    "                           ,\"Tweet Text\"      : TweetTextList\n",
    "                           ,\"Positive Score\"  : PositiveList\n",
    "                           ,\"Negative Score\"  : NegativeList                           \n",
    "                           ,\"Neutral Score\"   : NeutralList\n",
    "                           ,\"Compound Score\"  : CompoundList})\n",
    "\n",
    "print(f'News Mood Data Frame:\\n{\"*\"*25}')\n",
    "NewsMood_DF.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store output Data Frame as CSV\n",
    "NewsMood_DF.to_csv(\"Output/BP_Output_NewsMoodData.csv\" , index = False , header = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compound Sentiment Analysis Scatter Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Partition Data by News Outlet\n",
    "BBC_DF = NewsMood_DF.loc[NewsMood_DF[\"News Outlet\"] == \"@BBCWorld\"]\n",
    "CBS_DF = NewsMood_DF.loc[NewsMood_DF[\"News Outlet\"] == \"@CBSNews\"]\n",
    "CNN_DF = NewsMood_DF.loc[NewsMood_DF[\"News Outlet\"] == \"@CNN\"]\n",
    "FOX_DF = NewsMood_DF.loc[NewsMood_DF[\"News Outlet\"] == \"@FoxNews\"]\n",
    "NYT_DF = NewsMood_DF.loc[NewsMood_DF[\"News Outlet\"] == \"@nytimes\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a Scatter Plot\n",
    "BBC_TweetLag = BBC_DF[\"Tweet Lag\"]\n",
    "CBS_TweetLag = CBS_DF[\"Tweet Lag\"]\n",
    "CNN_TweetLag = CNN_DF[\"Tweet Lag\"]\n",
    "FOX_TweetLag = FOX_DF[\"Tweet Lag\"]\n",
    "NYT_TweetLag = NYT_DF[\"Tweet Lag\"]\n",
    "\n",
    "BBC_CompoundScore = BBC_DF[\"Compound Score\"]\n",
    "CBS_CompoundScore = CBS_DF[\"Compound Score\"]\n",
    "CNN_CompoundScore = CNN_DF[\"Compound Score\"]\n",
    "FOX_CompoundScore = FOX_DF[\"Compound Score\"]\n",
    "NYT_CompoundScore = NYT_DF[\"Compound Score\"]\n",
    "\n",
    "plt.scatter(BBC_TweetLag , BBC_CompoundScore , color = \"red\" ,\\\n",
    "            edgecolor = \"black\" , s = 100 , alpha = .9 , label = \"BBC\")\n",
    "plt.scatter(CBS_TweetLag , CBS_CompoundScore , color = \"green\" ,\\\n",
    "            edgecolor = \"black\" , s = 100 , alpha = .9 , label = \"CBS\")\n",
    "plt.scatter(CNN_TweetLag , CNN_CompoundScore , color = \"blue\" ,\\\n",
    "            edgecolor = \"black\" , s = 100 , alpha = .9 , label = \"CNN\")\n",
    "plt.scatter(FOX_TweetLag , FOX_CompoundScore , color = \"yellow\" ,\\\n",
    "            edgecolor = \"black\" , s = 100 , alpha = .9 , label = \"FOX NEWS\")\n",
    "plt.scatter(NYT_TweetLag , NYT_CompoundScore , color = \"magenta\" ,\\\n",
    "            edgecolor = \"black\" , s = 100 , alpha = .9 , label = \"NYT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Plot Attributes\n",
    "plt.title(\"Media Tweet Compound Sentiment Analysis\")\n",
    "plt.xlabel(\"Tweet Lag\")\n",
    "plt.ylabel(\"Tweet Compound Sentiment\")\n",
    "plt.xlim(-5 , 105)\n",
    "plt.ylim(-1.5 , 1.5)\n",
    "plt.legend(bbox_to_anchor = (1, 1) , title = \"News Outlet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save plot as output and show\n",
    "plt.savefig(\"Output/BP_Output_MediaTweetCompoundSentiment_ScatterPlot.png\" , bbox_inches = \"tight\")\n",
    "plt.show(subplots = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overall Sentiment Analysis Bar Chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate Average Compound score\n",
    "AvgBBC = BBC_DF[\"Compound Score\"].mean()\n",
    "AvgCBS = CBS_DF[\"Compound Score\"].mean()\n",
    "AvgCNN = CNN_DF[\"Compound Score\"].mean()\n",
    "AvgFOX = FOX_DF[\"Compound Score\"].mean()\n",
    "AvgNYT = NYT_DF[\"Compound Score\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create attribute list for chart\n",
    "OverallCompoundSentiment = [AvgBBC, AvgCBS, AvgCNN, AvgFOX, AvgNYT]\n",
    "NewOutletLabels = [\"BBC\", \"CBS\", \"CNN\", \"FOX\", \"NYT\"]\n",
    "x_Axis = np.arange(len(NewOutletLabels))\n",
    "BarColor = [\"red\", \"green\", \"blue\", \"yellow\", \"magenta\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate Bar Chart\n",
    "plt.bar(x_Axis , OverallCompoundSentiment , color = BarColor, align = \"center\")\n",
    "x_TicksLocation = [value for value in x_Axis]\n",
    "plt.xticks(x_TicksLocation , NewOutletLabels , rotation = \"vertical\")\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label Chart\n",
    "plt.title(\"Media Tweet Overall Sentiment Analysis\")\n",
    "plt.xlabel(\"News Outet\")\n",
    "plt.ylabel(\"Average Compound Score\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save figure\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"Output/BP_Output_MediaTweetOverallSentiment_BarChart.png\")\n",
    "plt.show(subplots = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
